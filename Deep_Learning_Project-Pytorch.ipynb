{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center' style=\"margin-bottom: 0px\"> An end to end implementation of a Machine Learning pipeline </h1>\n",
    "<h4 align='center' style=\"margin-top: 0px\"> SPANDAN MADAN</h4>\n",
    "<h4 align='center' style=\"margin-top: 0px\"> Visual Computing Group, Harvard University</h4>\n",
    "<h4 align='center' style=\"margin-top: 0px\"> Computer Science and Artificial Intelligence Laboratory, MIT</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center' style=\"margin-top: 0px\"><a href='https://github.com/Spandan-Madan/DeepLearningProject'>Link to Github Repo</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Introduction\n",
    "\n",
    "### Background\n",
    "In the fall of 2016, I was a Teaching Fellow (Harvard's version of TA) for the graduate class on \"Advanced Topics in Data Science (CS209/109)\" at Harvard University. I was in-charge of designing the class project given to the students, and this tutorial has been built on top of the project I designed for the class.\n",
    "\n",
    "### Why write yet another Tutorial on Machine Learning and Deep Learning?\n",
    "As a researcher on Computer Vision, I come across new blogs and tutorials on ML (Machine Learning) every day. However, most of them are just focussing on introducing the syntax and the terminology relevant to the field. For example - a 15 minute tutorial on Tensorflow using MNIST dataset, or a 10 minute intro to Deep Learning in Keras on Imagenet. \n",
    "\n",
    "While people are able to copy paste and run the code in these tutorials and feel that working in ML is really not that hard, it doesn't help them at all in using ML for their own purposes. For example, they never introduce you to how you can run the same algorithm on your own dataset. Or, how do you get the dataset if you want to solve a problem. Or, which algorithms do you use - Conventional ML, or Deep Learning? How do you evaluate your models performance? How do you write your own model, as opposed to choosing a ready made architecture? All these form fundamental steps in any Machine Learning pipeline, and it is these steps that take most of our time as ML practitioners. \n",
    "\n",
    "This tutorial breaks down the whole pipeline, and leads the reader through it step by step in an hope to empower you to actually use ML, and not just feel that it was not too hard. Needless to say, this will take much longer than 15-30 minutes. I believe a weekend would be a good enough estimate.\n",
    "\n",
    "### About the Author\n",
    "\n",
    "I am <a href=\"http://spandanmadan.com/\">Spandan Madan</a>, a graduate student at Harvard University working on Computer Vision. My research work is supervised collaboratively by Professor Hanspeter Pfister at Harvard, and Professor Aude Oliva at MIT. My current research focusses on using Computer Vision and Natural Language Techniques in tandem to build systems capable of reasoning using text and visual elements simultaneusly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Project Outline : Multi-Modal Genre Classification for Movies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wow, that title sounds like a handful, right? Let's break it down step by step.\n",
    "\n",
    "### Q.1. what do we mean by Classification?\n",
    "\n",
    "In machine learning, the task of classification means to use the available data to learn a <i>function</i> which can assign a category to a data point. For example, assign a genre to a movie, like \"Romantic Comedy\", \"Action\", \"Thriller\". Another example could be automatically assigning a category to news articles, like \"Sports\" and \"Politics\". \n",
    "\n",
    "### More Formally \n",
    "\n",
    "#### Given:\n",
    "- A data point $x_i$ \n",
    "- A set of categories $y_1,y_2...y_n$ that $x_i$ can belong to. <br>\n",
    "\n",
    "#### Task : \n",
    "Predict the correct category $y_k$ for a new data point $x_k$ not present in the given dataset.\n",
    "\n",
    "#### Problem : \n",
    "We don't know how the $x$ and $y$ are related mathematically.\n",
    "\n",
    "#### Assumption : \n",
    "We assume there exists a function $f$ relating $x$ and $y$ i.e. $f(x_i)=y_i$\n",
    "\n",
    "#### Approach : \n",
    "Since $f$ is not known, we learn a function $g$, which approximates $f$. \n",
    "\n",
    "#### Important consideration : \n",
    "- If $f(x_i)=g(x_i)=y_i$ for all $x_i$, then the two functions $f$ and $g$ are exactly equal. Needless to say, this won't realistically ever happen, and we'll only be able to approximate the true function $f$ using $g$. This means, sometimes the prediction $g(x_i)$ will not be correct. And essentially, our whole goal is to find a $g$ which makes a really low number of such errors. That's basically all that we're trying to do. \n",
    "\n",
    "- For the sake of completeness, I should mention that this is a specific kind of learning problem which we call \"Supervised Learning\". Also, the idea that $g$ approximates $f$ well for data not present in our dataset is called \"Generalization\". It is absolutely paramount that our model generalizes, or else all our claims will only be true about data we already have and our predictions will not be correct. \n",
    "\n",
    "- We will look into generalization a little bit more a little ahead in the tutorial. \n",
    "\n",
    "- Finally, There are several other kinds, but supervised learning is the most popular and well studied kind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.2. What's Multi-Modal Classification then?\n",
    "\n",
    "In the machine learning community, the term Multi-Modal is used to refer to multiple <i>kinds</i> of data. For example, consider a YouTube video. It can be thought to contain 3 different modalities -\n",
    "\n",
    "- The video frames (visual modality)\n",
    "- The audio clip of what's being spoken (audio modality)\n",
    "- Some videos also come with the transcription of the words spoken in the form of subtitles (textual modality)\n",
    "\n",
    "Consider, that I'm interested in classifying a song on YouTube as pop or rock. You can use any of the above 3 modalities to predict the genre - The video, the song itself, or the lyrics. But, needless to say, you can predict it much better if you could use all three simultaneously. This is what we mean by multi-modal classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For this project, we will be using visual and textual data to classify movie genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Outline\n",
    "\n",
    "- **Scraping a dataset** : The first step is to build a rich data set. We will collect textual and visual data for each movie.\n",
    "- **Data pre-processing**\n",
    "- **Non-deep Machine Learning models : Probabilistic and Max-Margin Classifiers.**\n",
    "- **Intuitive theory behind Deep Learning**\n",
    "- **Deep Models for Visual Data**\n",
    "- **Deep Models for Text**\n",
    "- **Potential Extensions**\n",
    "- **Food for Thought**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3. Building your very own DataSet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any machine learning algorithm to work, it is imperative that we collect data which is \"representative\". Now, let's take a moment to discuss what the word representative mean.\n",
    "\n",
    "### What data is good data? OR What do you mean by data being \"representative\"?\n",
    "Let's look at this from first principles. Mathematically, the premise of machine learning (to be precise, the strand of machine learning we'll be working with here) is that given input variable X, and an output variable y, **IF** there is a function such that g(X)=y, then if g is unknown, we can \"learn\" a function f which approximates g. At the very heart, its not at all different from what you may have earlier studied as \"curve fitting\". For example, if you're trying to predict someone's movie preferences then X can be information about the person's gender, age, nationality and so on, while y can be the genre they most like to listen to!\n",
    "\n",
    "Let's do a thought experiment. Consider the same example - I'm trying to predict people's movie preferences. I walk into a classroom today, and collect information about some students and their movie preferences. Now, I use that data to build a model. How well do you think I can predict my father's movie preferences? The answer is - probably not very well. Why? Intuitively, there was probably no one in the classroom who was my father's age. My model can tell me that as people go from age 18 to 30, they have a higher preference for documentaries over superhero movies. But does this trend continue at 55? Probably, they may start liking family dramas more. Probably they don't. In a nutshell, we cannot say with certainty, as our data tells us nothing about it. So, if the task was to make predictions about ANYONE's movie preferences, then the data collected from just undergraduates is NOT representative.\n",
    "\n",
    "Now, let's see why this makes sense Mathematically. Look at the graph below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/contour.png\">\n",
    "<center>Fig.1: Plot of a function we are trying to approximate(<a href=\"http://www.jzy3d.org/js/slider/images/ContourPlotsDemo.png\">source</a>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we consider that the variable plotted on the vertical axis is $y$, and the values of the 2 variables on the horizontal axes make the input vector $X$, then, our hope is that we are able to find a function $f$ which can approximate the function plotted here. If all the data I collect is such that $x_1$ belongs to (80,100) and $x_2$ belongs to (80,100), the learned function will only be able to learn the \"yellow-green dipping bellow\" part of the function.  Our function will never be able to predict the behavior in the \"red\" regions of the true function. So, in order to be able to learn a good function, we need data sampled from a diverse set of values of $x_1$ and x2. That would be representative data to learn this contour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we want to collect data which is representative of all possible movies that we want to make predictions about. Or else (which is often the case), we need to be aware of the limitations of the model we have trained, and the predictions we can make with confidence. The easiest way to do this is to only make predictions about the domain of data we collected the training data from. For example, in our case, let us start by assuming that our model will predict genres for only English movies. Now, the task is to collect data about a diverse collection of movies.\n",
    "\n",
    "So how do we get this data then? Neither google, nor any university has released such a dataset. We want to collect visual and textual data about these movies. The simple answer is to scrape it from the internet to build our own dataset. For the purpose of this project, we will use movie posters as our visual data, and movie plots as textual data. Using these, we will build a model that can predict movie genres! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will be scraping data from 2 different movie sources - IMDB and TMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>IMDB:http://www.imdb.com/</h3>\n",
    "\n",
    "For those unaware, IMDB is the primary source of information about movies on the internet. It is immensely rich with posters, reviews, synopsis, ratings and many other information on every movie. We will use this as our primary data source. \n",
    "\n",
    "<h3>TMDB:https://www.themoviedb.org/</h3>\n",
    "\n",
    "TMDB, or The Movie DataBase, is an open source version of IMDB, with a free to use API that can be used to collect information. You do need an API key, but it can be obtained for free by just making a request after making a free account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note - \n",
    "IMDB gives some information for free through the API, but doesn't release other information about movies. Here, we will keep it legal and only use information given to us for free and legally. However, scraping does reside on the moral fence, so to say. People often scrape data which isn't exactly publicly available for use from websites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/special/__init__.py:640: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ufuncs import *\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._solve_toeplitz import levinson\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/linalg/__init__.py:191: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._decomp_update import *\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/special/_ellip_harm.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ellip_harm_2 import _ellipsoid, _ellipsoid_norm\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/sparse/lil.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _csparsetools\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._traversal import breadth_first_order, depth_first_order, \\\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:171: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:172: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \\\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/optimize/_numdiff.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._group_columns import group_dense, group_sparse\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/interpolate/_bsplines.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _bspl\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/spatial/__init__.py:94: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ckdtree import *\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .qhull import *\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _voronoi\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/spatial/distance.py:121: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hausdorff\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/stats/_continuous_distns.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _stats\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/_libs/__init__.py:3: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/_libs/__init__.py:3: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (hashtable as _hashtable,\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from pandas._libs import (hashtable as _hashtable,\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos, lib\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from pandas._libs import algos, lib\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import hashing, tslib\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from pandas._libs import hashing, tslib\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/indexes/base.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (lib, index as libindex, tslib as libts,\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/indexes/base.py:6: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from pandas._libs import (lib, index as libindex, tslib as libts,\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/indexes/datetimelike.py:28: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs.period import Period\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/indexes/datetimelike.py:28: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from pandas._libs.period import Period\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/sparse/array.py:32: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.sparse as splib\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/sparse/array.py:32: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  import pandas._libs.sparse as splib\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/window.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.window as _window\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/window.py:36: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  import pandas._libs.window as _window\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/groupby.py:66: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import lib, groupby as libgroupby, Timestamp, NaT, iNaT\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/groupby.py:66: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from pandas._libs import lib, groupby as libgroupby, Timestamp, NaT, iNaT\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/reshape/reshape.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos as _algos, reshape as _reshape\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/core/reshape/reshape.py:30: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from pandas._libs import algos as _algos, reshape as _reshape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/io/parsers.py:43: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.parsers as parsers\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/pandas/io/parsers.py:43: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  import pandas._libs.parsers as parsers\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/cluster/vq.py:88: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _vq\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/scipy/cluster/hierarchy.py:178: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hierarchy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torchvision\n",
    "import urllib2\n",
    "import requests\n",
    "import json\n",
    "import imdb\n",
    "import time\n",
    "import itertools\n",
    "import wget\n",
    "import os\n",
    "import tmdbsimple as tmdb\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is a broad outline of technical steps to be done for data collection\n",
    "\n",
    "\n",
    "* Sign up for TMDB (themoviedatabase.org), and set up API to scrape movie posters for above movies.\n",
    "* Set up and work with TMDb to get movie information from their database\n",
    "* Do the same for IMDb\n",
    "* Compare the entries of IMDb and TMDb for a movie\n",
    "* Get a listing and information of a few movies\n",
    "* Think and ponder over the potential challenges that may come our way, and think about interesting questions we can answer given the API's we have in our hands.\n",
    "* Get data from the TMDb\n",
    "\n",
    "Let's go over each one of these one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signing up for TMDB and getting set up for getting movie metadata.\n",
    "\n",
    "* Step 1. Head over to [tmdb.org] (https://www.themoviedb.org/?language=en) and create a new account there by signing up.\n",
    "* Step 2. Click on your account icon on the top right, then from drop down menu select \"Settings\".\n",
    "* Step 3. On the settings page, you will see the option \"API\" on the left pane. Click on that.\n",
    "* Step 4. Apply for a new developer key. Fill out the form as required. The fields \"Application Name\" and \"Application URL\" are not important. Fill anything there.\n",
    "* Step 5. It should generate a new API key for you and you should also receive a mail.\n",
    "\n",
    "Now that you have the API key for TMDB, you can query using TMDB. Remember, it allows only 40 queries per 10 seconds.\n",
    "\n",
    "An easy way to respect this is to just have a call to <i>time.sleep(1)</i> after each iteration. This is also being very nice to the server.\n",
    "\n",
    "If you want to try and maximize your throughput you can embed every TMDB request in a nested try except block. If the first try fails, the second try first uses python's sleep function to give it a little rest, and then try again to make a request. Something like this -\n",
    "\t\n",
    "~~~~\n",
    "try:\n",
    "    search.movie(query=movie) #An API request\n",
    "except:\n",
    "    try:\n",
    "        time.sleep(10) #sleep for a bit, to give API requests a rest.\n",
    "        search.movie(query=<i>movie_name</i>) #Make second API request\n",
    "    except:\n",
    "        print \"Failed second attempt too, check if there's any error in request\"\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TMDB using the obtained API Key to get movie information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have made these functions which make things easy. Basically, I'm making use of a library called tmdbsimple which makes TMDB using even easier. This library was installed at the time of setup.\n",
    "\n",
    "However, if you  want to avoid the library, it is also easy enough to load the API output directly into a dictionary like this without using tmdbsimple:\n",
    "\n",
    "~~~\n",
    "url = 'https://api.themoviedb.org/3/movie/1581?api_key=' + api_key\n",
    "data = urllib2.urlopen(url).read()\n",
    "\n",
    "# create dictionary from JSON \n",
    "dataDict = json.loads(data)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists\n"
     ]
    }
   ],
   "source": [
    "# set here the path where you want the scraped folders to be saved!\n",
    "poster_folder='posters_final/'\n",
    "if poster_folder.split('/')[0] in os.listdir('./'):\n",
    "    print('Folder already exists')\n",
    "else:\n",
    "    os.mkdir('./'+poster_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'posters_final/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of this example, i will be working with the 1999 Sci-Fi movie - \"The Matrix\"!\n",
    "import tmdbsimple as tmdb\n",
    "api_key = 'a237bfff7e08d0e6902c623978183be0' #Enter your own API key here to run the code below. \n",
    "# Generate your own API key as explained above :)\n",
    "\n",
    "\n",
    "tmdb.API_KEY = api_key #This sets the API key setting for the tmdb object\n",
    "search = tmdb.Search() #this instantiates a tmdb \"search\" object which allows your to search for the movie\n",
    "import os.path\n",
    "# These functions take in a string movie name i.e. like \"The Matrix\" or \"Interstellar\"\n",
    "# What they return is pretty much clear in the name - Poster, ID , Info or genre of the Movie!\n",
    "def grab_poster_tmdb(movie):\n",
    "    response = search.movie(query=movie)\n",
    "    id=response['results'][0]['id']\n",
    "    movie = tmdb.Movies(id)\n",
    "    posterp=movie.info()['poster_path']\n",
    "    title=movie.info()['original_title']\n",
    "    if os.path.isfile(poster_folder+title+'.jpg '):\n",
    "        return\n",
    "    url='image.tmdb.org/t/p/original'+posterp\n",
    "    title='_'.join(title.split(' '))\n",
    "    strcmd='wget -O '+poster_folder+title+'.jpg '+url\n",
    "    os.system(strcmd)\n",
    "\n",
    "def get_movie_id_tmdb(movie):\n",
    "    response = search.movie(query=movie)\n",
    "    movie_id=response['results'][0]['id']\n",
    "    return movie_id\n",
    "\n",
    "def get_movie_info_tmdb(movie):\n",
    "    response = search.movie(query=movie)\n",
    "    id=response['results'][0]['id']\n",
    "    movie = tmdb.Movies(id)\n",
    "    info=movie.info()\n",
    "    return info\n",
    "\n",
    "def get_movie_genres_tmdb(movie):\n",
    "    response = search.movie(query=movie)\n",
    "    id=response['results'][0]['id']\n",
    "    movie = tmdb.Movies(id)\n",
    "    genres=movie.info()['genres']\n",
    "    return genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the above functions have been made to make it easy to get genres, posters and ID, all the information that can be accessed can be seen by calling the function get_movie_info() as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'id': 28, u'name': u'Action'}, {u'id': 878, u'name': u'Science Fiction'}]\n"
     ]
    }
   ],
   "source": [
    "print get_movie_genres_tmdb(\"The Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the Movie information from TMDB gets stored in a dictionary with the following keys for easy access -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'poster_path',\n",
       " u'production_countries',\n",
       " u'revenue',\n",
       " u'overview',\n",
       " u'video',\n",
       " u'id',\n",
       " u'genres',\n",
       " u'title',\n",
       " u'tagline',\n",
       " u'vote_count',\n",
       " u'homepage',\n",
       " u'belongs_to_collection',\n",
       " u'original_language',\n",
       " u'status',\n",
       " u'spoken_languages',\n",
       " u'imdb_id',\n",
       " u'adult',\n",
       " u'backdrop_path',\n",
       " u'production_companies',\n",
       " u'release_date',\n",
       " u'popularity',\n",
       " u'original_title',\n",
       " u'budget',\n",
       " u'vote_average',\n",
       " u'runtime']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info=get_movie_info_tmdb(\"The Matrix\")\n",
    "print \"All the Movie information from TMDB gets stored in a dictionary with the following keys for easy access -\"\n",
    "info.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, to get the tagline of the movie we can use the above dictionary key - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Real World.\n"
     ]
    }
   ],
   "source": [
    "info=get_movie_info_tmdb(\"The Matrix\")\n",
    "print info['tagline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting movie information from IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to get information from TMDB, here's how we can get information about the same movie from IMDB. This makes it possible for us to combine more information, and get a richer dataset. I urge you to try and see what dataset you can make, and go above and beyond the basic things I've done in this tutorial. Due to the differences between the two datasets, you will have to do some cleaning, however both of these datasets are extremely clean and it will be minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the information we can get about this movie from IMDB-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'production managers',\n",
       " u'rating',\n",
       " u'casting directors',\n",
       " u'distributors',\n",
       " u'music department',\n",
       " u'runtimes',\n",
       " u'special effects',\n",
       " u'year',\n",
       " u'color info',\n",
       " u'composers',\n",
       " u'costume designers',\n",
       " u'votes',\n",
       " u'top 250 rank',\n",
       " u'title',\n",
       " u'writer',\n",
       " u'editors',\n",
       " u'visual effects',\n",
       " u'cinematographers',\n",
       " u'writers',\n",
       " u'camera department',\n",
       " u'directors',\n",
       " u'certificates',\n",
       " u'countries',\n",
       " u'country codes',\n",
       " u'language codes',\n",
       " u'production designers',\n",
       " u'director',\n",
       " u'casting department',\n",
       " u'special effects companies',\n",
       " u'assistant directors',\n",
       " u'sound mix',\n",
       " u'location management',\n",
       " u'genres',\n",
       " u'miscellaneous',\n",
       " u'production companies',\n",
       " u'producers',\n",
       " u'set decorators',\n",
       " u'original air date',\n",
       " u'costume departmen',\n",
       " u'akas',\n",
       " u'aspect ratio',\n",
       " u'sound department',\n",
       " u'stunts',\n",
       " u'kind',\n",
       " u'make up department',\n",
       " u'other companies',\n",
       " u'art department',\n",
       " u'languages',\n",
       " u'transportation department',\n",
       " u'plot outline',\n",
       " u'plot',\n",
       " u'cast',\n",
       " u'synopsis',\n",
       " u'art directors',\n",
       " u'animation department',\n",
       " u'cover url',\n",
       " u'editorial department',\n",
       " u'canonical title',\n",
       " u'long imdb title',\n",
       " u'long imdb canonical title',\n",
       " u'smart canonical title',\n",
       " u'smart long imdb canonical title',\n",
       " u'full-size cover url']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import imdb\n",
    "# Create the IMDB object that will be used to access the IMDb's database.\n",
    "imbd_object = imdb.IMDb() # by default access the web.\n",
    "\n",
    "# Search for a movie (get a list of Movie objects).\n",
    "results = imbd_object.search_movie('The Matrix')\n",
    "#print(len(results))\n",
    "# As this returns a list of all movies containing the word \"The Matrix\", we pick the first element\n",
    "movie = results[0]\n",
    "\n",
    "imbd_object.update(movie)\n",
    "\n",
    "print \"All the information we can get about this movie from IMDB-\"\n",
    "movie.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The genres associated with the movie are -  [u'Action', u'Sci-Fi']\n"
     ]
    }
   ],
   "source": [
    "print \"The genres associated with the movie are - \",movie['genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A small comparison of IMDB and TMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have both systems running, let's do a very short comparison for the same movie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The genres for The Matrix pulled from IMDB are - [u'Action', u'Sci-Fi']\n",
      "The genres for The Matrix pulled from TMDB are - [{u'id': 28, u'name': u'Action'}, {u'id': 878, u'name': u'Science Fiction'}]\n"
     ]
    }
   ],
   "source": [
    "print \"The genres for The Matrix pulled from IMDB are -\",movie['genres']\n",
    "print \"The genres for The Matrix pulled from TMDB are -\",get_movie_genres_tmdb(\"The Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, both the systems are correct, but the way they package information is different. TMDB calls it \"Science Fiction\" and has an ID for every genre. While IMDB calls it \"Sci-Fi\". Thus, it is important to keep track of these things when making use of both the datasets simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to scrape information for one movie, let's take a bigger step towards scraping multiple movies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with multiple movies : Obtaining Top 20 movies from TMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first instantiate an object that inherits from class Movies from TMDB. Then We use the **popular()** class method (i.e. function) to get top movies. To get more than one page of results, the optional page argument lets us see movies from any specified page number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "all_movies=tmdb.Movies()\n",
    "top_movies=all_movies.popular()\n",
    "\n",
    "# This is a dictionary, and to access results we use the key 'results' which returns info on 20 movies\n",
    "print(len(top_movies['results']))\n",
    "top20_movs=top_movies['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one of these movies. It's the same format as above, as we had information on the movie \"The Matrix\", as you can see below. It's a dictionary which can be queried  for specific information on that movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is all the information you can get on this movie - \n",
      "{u'poster_path': u'/3IGbjc5ZC5yxim5W0sFING2kdcz.jpg', u'title': u'Solo: A Star Wars Story', u'overview': u'Through a series of daring escapades deep within a dark and dangerous criminal underworld, Han Solo meets his mighty future copilot Chewbacca and encounters the notorious gambler Lando Calrissian.', u'release_date': u'2018-05-15', u'popularity': 223.512, u'original_title': u'Solo: A Star Wars Story', u'backdrop_path': u'/96B1qMN9RxrAFu6uikwFhQ6N6J9.jpg', u'vote_count': 1782, u'video': False, u'adult': False, u'vote_average': 6.7, u'genre_ids': [28, 12, 878], u'id': 348350, u'original_language': u'en'}\n",
      "\n",
      "\n",
      "The title of the first movie is -  Solo: A Star Wars Story\n"
     ]
    }
   ],
   "source": [
    "first_movie=top20_movs[0]\n",
    "print \"Here is all the information you can get on this movie - \"\n",
    "print first_movie\n",
    "print \"\\n\\nThe title of the first movie is - \", first_movie['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out top 5 movie's titles! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solo: A Star Wars Story\n",
      "The Nun\n",
      "The Predator\n",
      "Avengers: Infinity War\n",
      "The First Purge\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(top20_movs)):\n",
    "    mov=top20_movs[i]\n",
    "    title=mov['title']\n",
    "    print title\n",
    "    if i==4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yes, I know. I'm a little upset too seeing The Nun above Avengers: Infinity War! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on, we can get their genres the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 12, 878]\n",
      "[27, 9648, 53]\n",
      "[27, 878, 28, 35]\n",
      "[12, 878, 28]\n",
      "[28, 878, 53, 27]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(top20_movs)):\n",
    "    mov=top20_movs[i]\n",
    "    genres=mov['genre_ids']\n",
    "    print genres\n",
    "    if i==4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, TMDB doesn't want to make your job as easy as you thought. Why these random numbers? Want to see their genre names? Well, there's the Genre() class for it. Let's get this done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tmdb genre object!\n",
    "genres=tmdb.Genres()\n",
    "# the list() method of the Genres() class returns a listing of all genres in the form of a dictionary.\n",
    "list_of_genres=genres.list()['genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert this list into a nice dictionary to look up genre names from genre IDs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genre_ID_to_name={}\n",
    "for i in range(len(list_of_genres)):\n",
    "    genre_id=list_of_genres[i]['id']\n",
    "    genre_name=list_of_genres[i]['name']\n",
    "    Genre_ID_to_name[genre_id]=genre_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's re-print the genres of top 20 movies? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solo: A Star Wars Story [u'Action', u'Adventure', u'Science Fiction']\n",
      "The Nun [u'Horror', u'Mystery', u'Thriller']\n",
      "The Predator [u'Horror', u'Science Fiction', u'Action', u'Comedy']\n",
      "Avengers: Infinity War [u'Adventure', u'Science Fiction', u'Action']\n",
      "The First Purge [u'Action', u'Science Fiction', u'Thriller', u'Horror']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(top20_movs)):\n",
    "    mov=top20_movs[i]\n",
    "    title=mov['title']\n",
    "    genre_ids=mov['genre_ids']\n",
    "    genre_names=[]\n",
    "    for id in genre_ids:\n",
    "        genre_name=Genre_ID_to_name[id]\n",
    "        genre_names.append(genre_name)\n",
    "    print title,genre_names\n",
    "    if i==4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4 - Building a dataset to work with : Let's take a look at the top 1000 movies from the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making use of the same api as before, we will just pull results from the top 50 pages. As mentioned earlier, the \"page\" attribute of the command top_movies=all_movies.popular() can be used for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note: Some of the code below will store the data into python \"pickle\" files so that it can be ready directly from memory, as opposed to being downloaded every time. Once done, you should comment out any code which generated an object that was pickled and is no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movies=tmdb.Movies()\n",
    "top_movies=all_movies.popular()\n",
    "\n",
    "# This is a dictionary, and to access results we use the key 'results' which returns info on 20 movies\n",
    "len(top_movies['results'])\n",
    "top20_movs=top_movies['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling movie list, Please wait...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Comment out this cell once the data is saved into pickle file.\n",
    "all_movies=tmdb.Movies()\n",
    "top1000_movies=[]\n",
    "print('Pulling movie list, Please wait...')\n",
    "for i in range(1,51):\n",
    "    if i%15==0:\n",
    "        time.sleep(7)\n",
    "    movies_on_this_page=all_movies.popular(page=i)['results']\n",
    "    top1000_movies.extend(movies_on_this_page)\n",
    "len(top1000_movies)\n",
    "f3=open('movie_list.pckl','wb')\n",
    "pickle.dump(top1000_movies,f3)\n",
    "f3.close()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3=open('movie_list.pckl','rb')\n",
    "top1000_movies=pickle.load(f3)\n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise analysis of Movie Genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our dataset is multi label, simply looking at the distribution of genres is not sufficient. It might be beneficial to see which genres co-occur, as it might shed some light on inherent biases in our dataset. For example, it would make sense if romance and comedy occur together more often than documentary and comedy. Such inherent biases tell us that the underlying population we are sampling from itself is skewed and not balanced. We may then take steps to account for such problems. Even if we don't take such steps, it is important to be aware that we are making the assumption that an unbalanced dataset is not hurting our performance and if need be, we can come back to address this assumption. Good old scientific method, eh?\n",
    "\n",
    "So for the top 1000 movies let's do some pairwise analysis for genre distributions. Our main purpose is to see which genres occur together in the same movie. So, we first define a function which takes a list and makes all possible pairs from it. Then, we pull the list of genres for a movie and run this function on the list of genres to get all pairs of genres which occur together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function just generates all possible pairs of movies\n",
    "def list2pairs(l):\n",
    "    # itertools.combinations(l,2) makes all pairs of length 2 from list l.\n",
    "    pairs = list(itertools.combinations(l, 2))\n",
    "    # then the one item pairs, as duplicate pairs aren't accounted for by itertools\n",
    "    for i in l:\n",
    "        pairs.append([i,i])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, now we will pull genres for each movie, and use above function to count occurrences of when two genres occurred together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all genre lists pairs from all movies\n",
    "allPairs = []\n",
    "for movie in top1000_movies:\n",
    "    allPairs.extend(list2pairs(movie['genre_ids']))\n",
    "    \n",
    "nr_ids = np.unique(allPairs)\n",
    "visGrid = np.zeros((len(nr_ids), len(nr_ids)))\n",
    "for p in allPairs:\n",
    "    visGrid[np.argwhere(nr_ids==p[0]), np.argwhere(nr_ids==p[1])]+=1\n",
    "    if p[1] != p[0]:\n",
    "        visGrid[np.argwhere(nr_ids==p[1]), np.argwhere(nr_ids==p[0])]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the structure we just made. It is a 19X19 structure, as shown below. Also, see that we had 19 Genres. Needless to say, this structure counts the number of simultaneous occurrences of genres in same movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 19)\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print visGrid.shape\n",
    "print len(Genre_ID_to_name.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x127814810>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAE9CAYAAACiDN36AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEATByPh/K5dfbgyX87YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125bcc510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_lookup = []\n",
    "for i in xrange(len(nr_ids)):\n",
    "    annot_lookup.append(Genre_ID_to_name[nr_ids[i]])\n",
    "\n",
    "sns.heatmap(visGrid, xticklabels=annot_lookup, yticklabels=annot_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above image shows how often the genres occur together, as a heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important thing to notice in the above plot is the diagonal. The diagonal corresponds to self-pairs, i.e. number of times a genre, say Drama occurred with Drama. Which is basically just a count of the total times that genre occurred! \n",
    "\n",
    "As we can see there are a lot of dramas in the data set, it is also a very unspecific label. There are nearly no documentaries or TV Movies. Horror is a very distinct label, and romance is also not too widely spread. \n",
    "\n",
    "To account for this unbalanced data, there are multiple things we can try to explore what interesting relationships can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delving Deeper into co-occurrence of genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want to do now is to look for nice groups of genres that co-occur, and see if it makes sense to us logically? Intuitively speaking, wouldn't it be fun if we saw nice boxes on the above plot - boxes of high intensity i.e. genres that occur together and don't occur much with other genres. In some ways, that would isolate the co-occurrence of some genres, and heighten the co-occurrence of others.\n",
    "\n",
    "While the data may not show that directly, we can play with the numbers to see if that's possible. The technique used for that is called biclustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/__init__.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/__init__.py:10: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/extmath.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/extmath.py:24: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/extmath.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sparsefuncs_fast import csr_row_norms\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/extmath.py:26: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from .sparsefuncs_fast import csr_row_norms\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/metrics/cluster/supervised.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .expected_mutual_info_fast import expected_mutual_information\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/metrics/cluster/supervised.py:24: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from .expected_mutual_info_fast import expected_mutual_information\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/metrics/pairwise.py:29: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .pairwise_fast import _chi2_kernel_fast, _sparse_manhattan\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/metrics/pairwise.py:29: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from .pairwise_fast import _chi2_kernel_fast, _sparse_manhattan\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ball_tree import BallTree\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from .ball_tree import BallTree\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/neighbors/__init__.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .kd_tree import KDTree\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/neighbors/__init__.py:7: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from .kd_tree import KDTree\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/random.py:12: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._random import sample_without_replacement\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/random.py:12: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from ._random import sample_without_replacement\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/graph.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .graph_shortest_path import graph_shortest_path\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/graph.py:17: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from .graph_shortest_path import graph_shortest_path\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/sparsetools/__init__.py:3: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._traversal import connected_components\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/sparsetools/__init__.py:3: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from ._traversal import connected_components\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/sparsetools/_graph_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._graph_tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/utils/sparsetools/_graph_validation.py:5: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from ._graph_tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/linear_model/base.py:35: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ..utils.seq_dataset import ArrayDataset, CSRDataset\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/linear_model/base.py:35: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from ..utils.seq_dataset import ArrayDataset, CSRDataset\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/linear_model/least_angle.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ..utils import arrayfuncs, as_float_array, check_X_y\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/linear_model/least_angle.py:24: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from ..utils import arrayfuncs, as_float_array, check_X_y\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:29: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import cd_fast\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:29: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from . import cd_fast\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/linear_model/__init__.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/linear_model/__init__.py:22: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/linear_model/sag.py:14: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sag_fast import sag\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/linear_model/sag.py:14: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from .sag_fast import sag\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/svm/base.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import libsvm, liblinear\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/svm/base.py:8: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from . import libsvm, liblinear\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/svm/base.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import libsvm_sparse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/svm/base.py:9: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from . import libsvm_sparse\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:28: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._online_lda import (mean_change, _dirichlet_expectation_1d,\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:28: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from ._online_lda import (mean_change, _dirichlet_expectation_1d,\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/isotonic.py:13: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._isotonic import _inplace_contiguous_isotonic_regression, _make_unique\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/isotonic.py:13: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from ._isotonic import _inplace_contiguous_isotonic_regression, _make_unique\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/manifold/t_sne.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _utils\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/manifold/t_sne.py:23: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from . import _utils\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/manifold/t_sne.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _barnes_hut_tsne\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/manifold/t_sne.py:24: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from . import _barnes_hut_tsne\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:37: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _k_means\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:37: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from . import _k_means\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:38: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._k_means_elkan import k_means_elkan\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:38: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from ._k_means_elkan import k_means_elkan\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hierarchical\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/cluster/hierarchical.py:23: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from . import _hierarchical\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/cluster/dbscan_.py:20: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._dbscan_inner import dbscan_inner\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/cluster/dbscan_.py:20: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from ._dbscan_inner import dbscan_inner\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import SpectralCoclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAFJCAYAAAAyv5ItAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127814390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SpectralCoclustering(n_clusters=5)\n",
    "model.fit(visGrid)\n",
    "\n",
    "fit_data = visGrid[np.argsort(model.row_labels_)]\n",
    "fit_data = fit_data[:, np.argsort(model.column_labels_)]\n",
    "\n",
    "annot_lookup_sorted = []\n",
    "for i in np.argsort(model.row_labels_):\n",
    "    annot_lookup_sorted.append(Genre_ID_to_name[nr_ids[i]])\n",
    "    \n",
    "sns.heatmap(fit_data, xticklabels=annot_lookup_sorted, yticklabels=annot_lookup_sorted, annot=False)\n",
    "plt.title(\"After biclustering; rearranged to show biclusters\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above figure, \"boxes\" or groups of movie genres automatically emerge! \n",
    "\n",
    "Intuitively - Crime, Sci-Fi, Mystery, Action, Horror, Drama, Thriller, etc co-occur. \n",
    "AND, Romance, Fantasy, Family, Music, Adventure, etc co-occur. \n",
    "\n",
    "That makes a lot of intuitive sense, right?\n",
    "\n",
    "One challenge is the broad range of the drama genre. It makes the two clusters highly overlapping. If we merge it together with action thriller, etc. We will end up with nearly all movies just having that label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on playing around with the stuff above, we can sort the data into the following genre categories - \"Drama, Action, ScienceFiction, exciting(thriller, crime, mystery), uplifting(adventure, fantasy, animation, comedy, romance, family), Horror, History\"**\n",
    "\n",
    "\n",
    "Note: that this categorization is subjective and by no means the only right solution. One could also just stay with the original labels and only exclude the ones with not enough data. Such tricks are important to balance the dataset, it allows us to increase or decrease the strength of certain signals, making it possible to improve our inferences :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting Questions\n",
    "This really should be a place for you to get creative and hopefully come up with better questions than me. \n",
    "\n",
    "Here are some of my thoughts:\n",
    "- Which actors are bound to a genre, and which can easily hop genres?\n",
    "- Is there a trend in genre popularity over the years?\n",
    "- Can you use sound tracks to identify the genre of a movie?\n",
    "- Are top romance actors higher paid than top action actors?\n",
    "- If you look at release date vs popularity score, which movie genres have a longer shelf life?\n",
    "\n",
    "Ideas to explore specifically for feature correlations:\n",
    "- Are title length correlated with movie genre?\n",
    "- Are movie posters darker for horror than for romance end comedy?\n",
    "- Are some genres specifically released more often at a certain time of year? \n",
    "- Is the RPG rating correlated with the genre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on this new category set, we will now pull posters from TMDB as our training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pulling movies from TMDB. If you want to debug, uncomment the print command. This will take a while, please wait...\n",
      "Pulled movies for genres - 12,14,16,18,27,28,35,36,37,53,80,99,878,9648,10402,10749,10751,10752,10770\n"
     ]
    }
   ],
   "source": [
    "# Done before, reading from pickle file now to maintain consistency of data!\n",
    "# We now sample 100 movies per genre. Problem is that the sorting is by popular movies, so they will overlap. \n",
    "# Need to exclude movies that were already sampled. \n",
    "movies = []\n",
    "baseyear = 2017\n",
    "\n",
    "print('Starting pulling movies from TMDB. If you want to debug, uncomment the print command. This will take a while, please wait...')\n",
    "done_ids=[]\n",
    "for g_id in nr_ids:\n",
    "    #print('Pulling movies for genre ID '+g_id)\n",
    "    baseyear -= 1\n",
    "    for page in xrange(1,6,1):\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "        url = 'https://api.themoviedb.org/3/discover/movie?api_key=' + api_key\n",
    "        url += '&language=en-US&sort_by=popularity.desc&year=' + str(baseyear) \n",
    "        url += '&with_genres=' + str(g_id) + '&page=' + str(page)\n",
    "\n",
    "        data = urllib2.urlopen(url).read()\n",
    "\n",
    "        dataDict = json.loads(data)\n",
    "        movies.extend(dataDict[\"results\"])\n",
    "    done_ids.append(str(g_id))\n",
    "print(\"Pulled movies for genres - \"+','.join(done_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "f6=open(\"movies_for_posters\",'wb')\n",
    "pickle.dump(movies,f6)\n",
    "f6.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f6=open(\"movies_for_posters\",'rb')\n",
    "movies=pickle.load(f6)\n",
    "f6.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove any duplicates that we have in the list of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "originally we had  1782  movies\n",
      "1698\n",
      "After removing duplicates we have  1698  movies\n"
     ]
    }
   ],
   "source": [
    "movie_ids = [m['id'] for m in movies]\n",
    "print \"originally we had \",len(movie_ids),\" movies\"\n",
    "movie_ids=np.unique(movie_ids)\n",
    "print len(movie_ids)\n",
    "seen_before=[]\n",
    "no_duplicate_movies=[]\n",
    "for i in range(len(movies)):\n",
    "    movie=movies[i]\n",
    "    id=movie['id']\n",
    "    if id in seen_before:\n",
    "        continue\n",
    "#         print \"Seen before\"\n",
    "    else:\n",
    "        seen_before.append(id)\n",
    "        no_duplicate_movies.append(movie)\n",
    "print \"After removing duplicates we have \",len(no_duplicate_movies), \" movies\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's remove movies for which we have no posters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total movies : ', 1782)\n",
      "Started downloading posters...\n",
      "0\n",
      "Downloaded first. Code is working fine. Please wait, this will take quite some time...\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "Done with  300  movies!\n",
      "Trying to get poster for  The Dark Knight Rises\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "Done with  600  movies!\n",
      "Trying to get poster for  Shrek\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "Done with  900  movies!\n",
      "Trying to get poster for  The Kingdom\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "Done with  1200  movies!\n",
      "Trying to get poster for  Re: Cutie Honey\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "Done with  1500  movies!\n",
      "Trying to get poster for  Riding in Cars with Boys\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "Done with all the posters!\n"
     ]
    }
   ],
   "source": [
    "poster_movies=[]\n",
    "counter=0\n",
    "movies_no_poster=[]\n",
    "print(\"Total movies : \",len(movies))\n",
    "print(\"Started downloading posters...\")\n",
    "for movie in movies:\n",
    "    if counter%10==0:\n",
    "        print(counter)\n",
    "    id=movie['id']\n",
    "    title=movie['title']\n",
    "    if counter==1:\n",
    "        print('Downloaded first. Code is working fine. Please wait, this will take quite some time...')\n",
    "    if counter%300==0 and counter!=0:\n",
    "        print \"Done with \",counter,\" movies!\"\n",
    "        print \"Trying to get poster for \",title\n",
    "    try:\n",
    "        #grab_poster_tmdb(title)\n",
    "        poster_movies.append(movie)\n",
    "    except:\n",
    "        try:\n",
    "            time.sleep(7)\n",
    "            grab_poster_tmdb(title)\n",
    "            poster_movies.append(movie)\n",
    "        except:\n",
    "            movies_no_poster.append(movie)\n",
    "    counter+=1\n",
    "print(\"Done with all the posters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1782\n"
     ]
    }
   ],
   "source": [
    "print len(movies_no_poster)\n",
    "print len(poster_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('poster_movies.pckl','w')\n",
    "pickle.dump(poster_movies,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('poster_movies.pckl','r')\n",
    "poster_movies=pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('no_poster_movies.pckl','w')\n",
    "pickle.dump(movies_no_poster,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('no_poster_movies.pckl','r')\n",
    "movies_no_poster=pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations, we are done scraping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a dataset out of the scraped information!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is simple, but **extremely** important. It's basically what will set the stage for the whole project. Given that you have the freedom to cast their own project within the framework I am providing, there are many decisions that you must make to finalize **your own version** of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are working on a **classification** problem, we need to make two decisions given the data at hand - \n",
    "* What do we want to predict, i.e. what's our Y?\n",
    "* What features to use for predicting this Y, i.e. what X should we use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different options possible, and it comes down to you to decide what's most exciting. I will be picking my own version for the example, **but it is imperative that you think this through, and come up with a version which excites you!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, here are some possible ways to frame Y, while still sticking to the problem of genre prediction -\n",
    "\n",
    "* Assume every movie can have multiple genres, and then it becomes a multi-label classification problem. For example, a movie can be Action, Horror and Adventure simultaneously. Thus, every movie can be more than one genre.\n",
    "\n",
    "* Make clusters of genres as we did in Milestone 1 using biclustering, and then every movie can have only 1 genre. This way, the problem becomes a simpler, multi-class problem. For example, a movie could have the class - Uplifting (refer Milestone 1), or Horror or History. No movie get's more than one class.\n",
    "\n",
    "For the purposes of this implementation, I'm going with the first case explained above - i.e. a multi-label classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for designing our input features i.e. X, you may pick any features you think make sense, for example, the Director of a movie may be a good predictor for genre. OR, they may choose any features they design using algorithms like PCA. Given the richness of IMDB, TMDB and alternate sources like Wikipedia, there is a plethora of options available. **Be creative here!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important thing to note is that in doing so, we must also make many more small implementation decisions on the way. For example, what genres are we going to include? what movies are we going to include? All these are open ended!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation decisions made - \n",
    "* The problem is framed here as a multi-label problem explained above. \n",
    "* We will try to predict multiple genres associated with a movie. This will be our Y.\n",
    "* We will use 2 different kinds of X - text and images. \n",
    "* For the text part - Input features being used to predict the genre is a form of the movie's plot available from TMDB using the property 'overview'. This will be our X.\n",
    "* For the image part - we will use the scraped poster images as our X. \n",
    "\n",
    "NOTE : We will first look at some conventional machine learning models, which were popular before the recent rise of neural networks and deep learning. For the poster image to genre prediction, I have avoided using this for the reason that conventional ML models are simply not used anymore without using deep learning for feature extraction (all discussed in detail ahead, don't be scared by the jargon). For the movie overview to genre prediction problem we will look at both conventional models and deep learning models. \n",
    "\n",
    "Now, let's build our X and Y!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's identify movies that have overviews. **Next few steps are going to be a good example on why data cleaning is important!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1670"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_with_overviews=[]\n",
    "for i in range(len(no_duplicate_movies)):\n",
    "    movie=no_duplicate_movies[i]\n",
    "    id=movie['id']\n",
    "    overview=movie['overview']\n",
    "    \n",
    "    if len(overview)==0:\n",
    "        continue\n",
    "    else:\n",
    "        movies_with_overviews.append(movie)\n",
    "        \n",
    "len(movies_with_overviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's store the genre's for these movies in a list that we will later transform into a binarized vector. \n",
    "\n",
    "Binarized vector representation is a very common and important way data is stored/represented in ML. Essentially, it's a way to reduce a categorical variable with n possible values to n binary indicator variables. What does that mean? For example, let [(1,3),(4)] be the list saying that sample A has two labels 1 and 3, and sample B has one label 4. For every sample, for every possible label, the representation is simply 1 if it has that label, and 0 if it doesn't have that label. So the binarized version of the above list will be -\n",
    "~~~~~\n",
    "[(1,0,1,0]),\n",
    "(0,0,0,1])]\n",
    "~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genres=np.zeros((len(top1000_movies),3))\n",
    "genres=[]\n",
    "all_ids=[]\n",
    "for i in range(len(movies_with_overviews)):\n",
    "    movie=movies_with_overviews[i]\n",
    "    id=movie['id']\n",
    "    genre_ids=movie['genre_ids']\n",
    "    genres.append(genre_ids)\n",
    "    all_ids.extend(genre_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb=MultiLabelBinarizer()\n",
    "Y=mlb.fit_transform(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 12, 878, 53]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1670, 19)\n",
      "[354 261 251 673 222 451 445 137  45 449 259 140 273 192 134 238 289  99\n",
      " 124]\n"
     ]
    }
   ],
   "source": [
    "print Y.shape\n",
    "print np.sum(Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting. We started with only 19 genre labels if you remember. But the shape for Y is 1666,20 while it should be 1666,19 as there are only 19 genres? Let's explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find genre IDs that are not present in our original list of genres!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tmdb genre object!\n",
    "genres=tmdb.Genres()\n",
    "# the list() method of the Genres() class returns a listing of all genres in the form of a dictionary.\n",
    "list_of_genres=genres.list()['genres']\n",
    "Genre_ID_to_name={}\n",
    "for i in range(len(list_of_genres)):\n",
    "    genre_id=list_of_genres[i]['id']\n",
    "    genre_name=list_of_genres[i]['name']\n",
    "    Genre_ID_to_name[genre_id]=genre_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in set(all_ids):\n",
    "    if i not in Genre_ID_to_name.keys():\n",
    "        print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this genre ID wasn't given to us by TMDB when we asked it for all possible genres. How do we go about this now? We can either neglect all samples that have this genre. But if you look up you'll see there's too many of these samples. So, I googled more and went into their documentation and found that this ID corresponds to the genre \"Foreign\". So, we add it to the dictionary of genre names ourselves. Such problems are ubiquitous in machine learning, and it is up to us to diagnose and correct them. We must always make a decision about what to keep, how to store data and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genre_ID_to_name[10769]=\"Foreign\" #Adding it to the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Genre_ID_to_name.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we turn to building the X matrix i.e. the input features! As described earlier, we will be using the overview of movies as our input vector! Let's look at a movie's overview for example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overview for the movie The Martian  is - \n",
      "\n",
      "\n",
      "During a manned mission to Mars, Astronaut Mark Watney is presumed dead after a fierce storm and left behind by his crew. But Watney has survived and finds himself stranded and alone on the hostile planet. With only meager supplies, he must draw upon his ingenuity, wit and spirit to subsist and find a way to signal to Earth that he is alive.\n"
     ]
    }
   ],
   "source": [
    "sample_movie=movies_with_overviews[5]\n",
    "sample_overview=sample_movie['overview']\n",
    "sample_title=sample_movie['title']\n",
    "print \"The overview for the movie\",sample_title,\" is - \\n\\n\"\n",
    "print sample_overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, how do we store this movie overview in a matrix?\n",
    "\n",
    "#### Do we just store the whole string? We know that we need to work with numbers, but this is all text. What do we do?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we will be storing the X matrix is called a \"Bag of words\" representation. The basic idea of this representation in our context is that we can think of all the distinct words that are possible in the movies' reviews as a distinct object. And then every movie overview can be thought as a \"Bag\" containing a bunch of these possible objects.\n",
    "\n",
    "For example, in the case of Zootopia the movie above - The \"Bag\" contains the words (\"Determined\", \"to\", \"prove\", \"herself\"......\"the\", \"mystery\"). We make such lists for all movie overviews. Finally, we binarize again like we did above for Y. scikit-learn makes our job easy here by simply using a function CountVectorizer() because this representation is so often used in Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this means is that, for all the movies that we have the data on, we will first count all the unique words. Say, there's 30,000 unique words. Then we can represent every movie overview as a 30000x1 vector, where each position in the vector corresponds to the presence or absence of a particular word. If the word corresponding to that position is present in the overview, that position will have 1, otherwise it will be 0. \n",
    "\n",
    "Ex - if our vocabular was 4 words - \"I\",\"am\",\"a\",\"good\",\"boy\", then the representation for the sentence \"I am a boy\" would be [1 1 1 0 1], and for the sentence \"I am good\" would be [1 1 0 1 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/feature_extraction/hashing.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hashing\n",
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/feature_extraction/hashing.py:9: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from . import _hashing\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=[]\n",
    "for i in range(len(movies_with_overviews)):\n",
    "    movie=movies_with_overviews[i]\n",
    "    id=movie['id']\n",
    "    overview=movie['overview']\n",
    "    overview=overview.replace(',','')\n",
    "    overview=overview.replace('.','')\n",
    "    content.append(overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1670\n",
      "Deadpool tells the origin story of former Special Forces operative turned mercenary Wade Wilson who after being subjected to a rogue experiment that leaves him with accelerated healing powers adopts the alter ego Deadpool Armed with his new abilities and a dark twisted sense of humor Deadpool hunts down the man who nearly destroyed his life\n",
      "1670\n"
     ]
    }
   ],
   "source": [
    "print len(movies_with_overviews)\n",
    "print content[0]\n",
    "print len(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are all words equally important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At the cost of sounding \"Animal Farm\" inspired, I would say not all words are equally important. \n",
    "\n",
    "For example, let's consider the overview for the Matrix - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Set in the 22nd century, The Matrix tells the story of a computer hacker who joins a group of underground insurgents fighting the vast and powerful computers who now rule the earth.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movie_info_tmdb('The Matrix')['overview']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For \"The Matrix\" a word like \"computer\" is a stronger indicators of it being a Sci-Fi movie, than words like \"who\" or \"powerful\" or \"vast\". One way computer scientists working with natural language tackled this problem in the past (and it is still used very popularly) is what we call TF-IDF i.e. Term Frequence, Inverse Document Frequency. The basic idea here is that words that are strongly indicative of the content of a single document (every movie overview is a document in our case) are words that occur very frequently in that document, and very infrequently in all other documents. For example, \"Computer\" occurs twice here but probably will not in most other movie overviews. Hence, it is indicative. On the other hand, generic words like \"a\",\"and\",\"the\" will occur very often in all documents. Hence, they are not indicative. \n",
    "\n",
    "So, can we use this information to reduce our insanely high 30,000 dimensional vector representation to a smaller, more handle-able number? But first up, why should we even care? The answer is probably one of the most used phrases in ML - \"The Curse of Dimensionality\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Curse of Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This section is strongly borrowing from one of the greatest <a href=\"https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf\">ML papers I've ever read.</a>\n",
    "\n",
    "This expression was coined by Bellman in 1961 to refer to the fact that many algorithms that work fine in low dimensions become intractable when the input is high-dimensional. The reason for them not working in high dimensions is very strongly linked to what we discussed earlier - having a representative dataset. Consider this, you have a function $f$ dependent only one dependent variable $x$, and $x$ can only integer values from 1 to 100. Since it's one dimensional, it can be plotted on a line. To get a representative sample, you'd need to sample something like - $f(1),f(20),f(40),f(60),f(80),f(100)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's increase the dimensionality i.e. number of dependent variables and see what happens. Say, we have 2 variables $x_1$ and $x_2$, same possible as before - integers between 1 and 100. Now, instead of a line, we'll have a plane with $x_1$ and $x_2$ on the two axes. The interesting bit is that instead of 100 possible values of dependent variables like before, we now have 100,000 possible values! Basically, we can make 100x100 table of possible values of $x_1$ and $x_2$. Wow, that increased exponentially. Not just figuratively, but mathematically exponentially. Needless to say, to cover 5% of the space like we did before, we'd need to sample $f$ at 5000 values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 3 variables, it would be 100,000,000, and we'd need to sample at 500,000 points. That's already more than the number of data points we have for most training problems we will ever come across."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, as the dimensionality (number of features) of the examples grows, because a fixed-size training set covers a dwindling fraction of the input space. Even with a moderate dimension of 100 and a huge training set of a trillion examples, the latter covers only a fraction of about $10^{18}$ of the input space. This is what makes machine learning\n",
    "both necessary and hard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, yes, if some words are unimportant, we want to get rid of them and reduce the dimensionality of our X matrix. And the way we will do it is using TF-IDF to identify un-important words. Python let's us do this with just one line of code (And this is why you should spend more time reading maths, than coding!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The min_df paramter makes sure we exclude words that only occur very rarely\n",
    "# The default also is to exclude any words that occur in every movie description\n",
    "vectorize=CountVectorizer(max_df=0.95, min_df=0.005)\n",
    "X=vectorize.fit_transform(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are excluding all words that occur in too many or too few documents, as these are very unlikely to be discriminative. Words that only occur in one document most probably are names, and words that occur in nearly all documents are probably stop words. Note that the values here were not tuned using a validation set. They are just guesses. It is ok to do, because we didn't evaluate the performance of these parameters. In a strict case, for example for a publication, it would be better to tune these as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1670, 19)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, each movie's overview gets represented by a 1x1365 dimensional vector.\n",
    "\n",
    "Now, we are ready for the kill. Our data is cleaned, hypothesis is set (Overview can predict movie genre), and the feature/output vectors are prepped. Let's train some models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f4=open('X.pckl','wb')\n",
    "f5=open('Y.pckl','wb')\n",
    "pickle.dump(X,f4)\n",
    "pickle.dump(Y,f5)\n",
    "f6=open('Genredict.pckl','wb')\n",
    "pickle.dump(Genre_ID_to_name,f6)\n",
    "f4.close()\n",
    "f5.close()\n",
    "f6.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations, we have our data set ready!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note : As we are building our own dataset, and I didn't want you to spend all your time waiting for poster image downloads to finish, I am working with an EXTREMELY small dataset. That is why, the results we will see for the deep learning portion will not be spectacular as compared to conventional machine learning methods. If you want to see the real power, you should spend some more time scraping something of the order of 100,000 images, as opposed to 1000 odd like I am doing here. Quoting the paper I mentioned above -  MORE DATA BEATS A CLEVERER ALGORITHM.\n",
    "\n",
    "#### As the TA, I saw that most teams working on the project had data of the order of 100,000 movies. So, if you want to extract the power of these models, consider scraping a larger dataset than me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Section 5 - Non-deep, Conventional ML models with above data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a layout of what we will be doing - \n",
    "\n",
    "- We will implement two different models\n",
    "- We will decide a performance metric i.e. a quantitative method to be sure about how well difference models are doing. \n",
    "- Discussion of the differences between the models, their strengths, weaknesses, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed earlier, there are a LOT of implementation decisions to be made. Between feature engineering, hyper-parameter tuning, model selection and how interpretable do you want your model to be (Read : Bayesian vs Non-Bayesian approaches) a lot is to be decided. For example, some of these models could be: \n",
    "\n",
    "- Generalized Linear Models\n",
    "- SVM\n",
    "- Shallow (1 Layer, i.e. not deep) Neural Network\n",
    "- Random Forest\n",
    "- Boosting\n",
    "- Decision Tree\n",
    "\n",
    "Or go more bayesian:\n",
    "- Naive Bayes\n",
    "- Linear or Quadratic Discriminant Analysis\n",
    "- Bayesian Hierarchical models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list is endless, and not all models will make sense for the kind of problem you have framed for yourself. ** Think about which model best fits for your purpose.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes here, I will be showing the example of 2 very simple models, one picked from each category above - \n",
    "\n",
    "1. SVM\n",
    "2. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick overview of the whole pipeline coming below: \n",
    "    \n",
    "- A little bit of feature engineering\n",
    "- 2 different Models \n",
    "- Evaluation Metrics chosen\n",
    "- Model comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start with some feature engineering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engineering the right features depends on 2 key ideas. Firstly, what is it that you are trying to solve? For example, if you want to guess my music preferences and you try to train a super awesome model while giving it what my height is as input features, you're going to have no luck. On the other hand, giving it my Spotify playlist will solve the problem with any model. So, CONTEXT of the problem plays a role. \n",
    "\n",
    "Second, you can only represent based on the data at hand. Meaning, if you didn't have access to my Spotify playlist, but to my Facebook statuses - You know all my statuses about Harvard may not be useful. But if you represent me as my Facebook statuses which are YouTube links, that would also solve the problem. So, AVAILABILITY OF DATA at hand is the second factor. \n",
    "\n",
    "#### A nice way to think of it is to think that you start with the problem at hand, but design features constrained by the data you have available. If you have many independent features that each correlate well with the class, learning is easy. On the other hand, if the class is a very complex function of the features, you may not be able to learn it.\n",
    "\n",
    "\n",
    "In the context of this problem, we would like to predict the genre of a movie. what we have access to - movie overviews, which are text descriptions of the movie plot. The hypothesis makes sense, overview is a short description of the story and the story is clearly important in assigning genres to movies. \n",
    "\n",
    "So, let's improve our features by playing with the words in the overviews in our data. One interesting way to go back to what we discussed earlier - TF-IDF. We originally used it to filter words, but we can also assign the tf-idf values as \"importance\" values to words, as opposed to treating them all equally. Tf-idf simply tries to identify the assign a weightage to each word in the bag of words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the way it works is - Most movie descriptions have the word \"The\" in it. Obviously, it doesn't tell you anything special about it. So weightage should be inversely proportional to how many movies have the word in their description. This is the IDF part.\n",
    "\n",
    "On the other hand, for the movie interstellar, if the description has the word Space 5 times, and wormhole 2 times, then it's probably more about Space than about wormhole. Thus, space should have a high weightage. This is the TF part. \n",
    "\n",
    "We simply use TF-IDf to assign weightage to every word in the bag of words. Which makes sense, right? :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1670, 1223)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X)\n",
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide our X and Y matrices into train and test split. We train the model on the train split, and report the performance on the test split. Think of this like the questions you do in the problem sets v/s the exam. Of course, they are both (assumed to be) from the same population of questions. And doing well on Problem Sets is a good indicator that you'll do well in exams, but really, you must test before you can make any claims about you knowing the subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(X_tfidf.shape[0]) < 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf=X_tfidf[msk]\n",
    "X_test_tfidf=X_tfidf[~msk]\n",
    "Y_train=Y[msk]\n",
    "Y_test=Y[~msk]\n",
    "positions=range(len(movies_with_overviews))\n",
    "# print positions\n",
    "test_movies=np.asarray(positions)[~msk]\n",
    "# test_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),...refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(f1_score, average=micro), verbose=0),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel':['linear'], 'C':[0.01, 0.1, 1.0]}\n",
    "gridCV = GridSearchCV(SVC(class_weight='balanced'), parameters, scoring=make_scorer(f1_score, average='micro'))\n",
    "classif = OneVsRestClassifier(gridCV)\n",
    "\n",
    "classif.fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(362, 1223) (362, 19) (362, 19) 4\n",
      "[u'Action', u'Science Fiction', u'Thriller', u'Horror']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        81\n",
      "          1       0.43      0.54      0.47        69\n",
      "          2       0.32      0.51      0.39        51\n",
      "          3       0.61      0.44      0.51       154\n",
      "          4       0.45      0.56      0.50        59\n",
      "          5       0.57      0.66      0.61       106\n",
      "          6       0.42      0.58      0.49        91\n",
      "          7       0.31      0.36      0.33        28\n",
      "          8       1.00      0.20      0.33        10\n",
      "          9       0.52      0.47      0.49       106\n",
      "         10       0.52      0.62      0.57        56\n",
      "         11       0.65      0.52      0.58        29\n",
      "         12       0.46      0.36      0.40        53\n",
      "         13       0.24      0.42      0.30        40\n",
      "         14       0.67      0.50      0.57        28\n",
      "         15       0.38      0.72      0.50        46\n",
      "         16       0.45      0.63      0.52        59\n",
      "         17       0.00      0.00      0.00        27\n",
      "         18       0.00      0.00      0.00        31\n",
      "\n",
      "avg / total       0.43      0.46      0.43      1124\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predstfidf=classif.predict(X_test_tfidf)\n",
    "print X_test_tfidf.shape, Y_test.shape, predstfidf.shape, len(genre_names)\n",
    "print genre_names\n",
    "print classification_report(Y_test, predstfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the performance is by and large poorer for movies which are less represented like War and animation, and better for categories like Drama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numbers aside, let's look at our model's predictions for a small sample of movies from our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list=sorted(list(Genre_ID_to_name.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for i in range(X_test_tfidf.shape[0]):\n",
    "    pred_genres=[]\n",
    "    movie_label_scores=predstfidf[i]\n",
    "    #print len(movie_label_scores), movie_label_scores[18]\n",
    "#     print movie_label_scores\n",
    "    for j in range(len(movie_label_scores)):\n",
    "        #print j\n",
    "        if movie_label_scores[j]!=0:\n",
    "            genre=Genre_ID_to_name[genre_list[j]]\n",
    "            pred_genres.append(genre)\n",
    "    predictions.append(pred_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f=open('classifer_svc','wb')\n",
    "pickle.dump(classif,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVIE:  Star Trek \tPREDICTION:  Animation,Comedy,Thriller,Crime,Family\n",
      "MOVIE:  The Hobbit: The Battle of the Five Armies \tPREDICTION:  Fantasy,Drama,Horror,Romance\n",
      "MOVIE:  Kung Fury \tPREDICTION:  Animation,Romance\n",
      "MOVIE:  Hercules \tPREDICTION:  Drama,Crime,Romance\n",
      "MOVIE:  Justin and the Knights of Valour \tPREDICTION:  Animation,Horror,Comedy,Thriller\n",
      "MOVIE:  The Perks of Being a Wallflower \tPREDICTION:  Animation,Comedy,Family\n",
      "MOVIE:  Out of the Furnace \tPREDICTION:  Fantasy,Animation,Action,Family\n"
     ]
    }
   ],
   "source": [
    "for i in range(X_test_tfidf.shape[0]):\n",
    "    if i%50==0 and i!=0:\n",
    "        print 'MOVIE: ',movies_with_overviews[i]['title'],'\\tPREDICTION: ',','.join(predictions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our second model? The naive bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifnb = OneVsRestClassifier(MultinomialNB())\n",
    "classifnb.fit(X[msk].toarray(), Y_train)\n",
    "predsnb=classifnb.predict(X[~msk].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f2=open('classifer_nb','wb')\n",
    "pickle.dump(classifnb,f2)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsnb=[]\n",
    "for i in range(X_test_tfidf.shape[0]):\n",
    "    pred_genres=[]\n",
    "    movie_label_scores=predsnb[i]\n",
    "    for j in range(len(movie_label_scores)):\n",
    "        #print j\n",
    "        if movie_label_scores[j]!=0:\n",
    "            genre=Genre_ID_to_name[genre_list[j]]\n",
    "            pred_genres.append(genre)\n",
    "    predictionsnb.append(pred_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVIE:  Star Trek \tPREDICTION:  Animation,Comedy,Family\n",
      "MOVIE:  The Hobbit: The Battle of the Five Armies \tPREDICTION:  Drama,Comedy,Romance\n",
      "MOVIE:  Kung Fury \tPREDICTION:  Drama,Comedy\n",
      "MOVIE:  Hercules \tPREDICTION:  Drama\n",
      "MOVIE:  Justin and the Knights of Valour \tPREDICTION:  Horror,Comedy,Thriller,Mystery\n",
      "MOVIE:  The Perks of Being a Wallflower \tPREDICTION:  Animation,Comedy,Family\n",
      "MOVIE:  Out of the Furnace \tPREDICTION:  \n"
     ]
    }
   ],
   "source": [
    "for i in range(X_test_tfidf.shape[0]):\n",
    "    if i%50==0 and i!=0:\n",
    "        print 'MOVIE: ',movies_with_overviews[i]['title'],'\\tPREDICTION: ',','.join(predictionsnb[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the results seem promising, but how do we really compare the two models? We need to quantify our performance so that we can say which one's better. Takes us back to what we discussed right in the beginning - we're learning a function $g$ which can approximate the original unknown function $f$. For some values of $x_i$, the predictions will be wrong for sure, and we want to minimize it. \n",
    "\n",
    "For multi label systems, we often keep track of performance using \"Precision\" and \"Recall\". These are standard metrics, and you can google to read up more about them if you're new to these terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the standard precision recall metrics for evaluating our system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(gt,preds):\n",
    "    TP=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    for t in gt:\n",
    "        if t in preds:\n",
    "            TP+=1\n",
    "        else:\n",
    "            FN+=1\n",
    "    for p in preds:\n",
    "        if p not in gt:\n",
    "            FP+=1\n",
    "    if TP+FP==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/float(TP+FP)\n",
    "    if TP+FN==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/float(TP+FN)\n",
    "    return precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4652163904235728 0.47555248618784535\n"
     ]
    }
   ],
   "source": [
    "precs=[]\n",
    "recs=[]\n",
    "for i in range(len(test_movies)):\n",
    "    if i%1==0:\n",
    "        pos=test_movies[i]\n",
    "        test_movie=movies_with_overviews[pos]\n",
    "        gtids=test_movie['genre_ids']\n",
    "        gt=[]\n",
    "        for g in gtids:\n",
    "            g_name=Genre_ID_to_name[g]\n",
    "            gt.append(g_name)\n",
    "#         print predictions[i],movies_with_overviews[i]['title'],gt\n",
    "        a,b=precision_recall(gt,predictions[i])\n",
    "        precs.append(a)\n",
    "        recs.append(b)\n",
    "\n",
    "print np.mean(np.asarray(precs)),np.mean(np.asarray(recs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5181498289923704 0.515772165219679\n"
     ]
    }
   ],
   "source": [
    "precs=[]\n",
    "recs=[]\n",
    "for i in range(len(test_movies)):\n",
    "    if i%1==0:\n",
    "        pos=test_movies[i]\n",
    "        test_movie=movies_with_overviews[pos]\n",
    "        gtids=test_movie['genre_ids']\n",
    "        gt=[]\n",
    "        for g in gtids:\n",
    "            g_name=Genre_ID_to_name[g]\n",
    "            gt.append(g_name)\n",
    "#         print predictions[i],movies_with_overviews[i]['title'],gt\n",
    "        a,b=precision_recall(gt,predictionsnb[i])\n",
    "        precs.append(a)\n",
    "        recs.append(b)\n",
    "\n",
    "print np.mean(np.asarray(precs)),np.mean(np.asarray(recs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average precision and recall scores for our samples are pretty good! Models seem to be working! Also, we can see that the Naive Bayes performs outperforms SVM. **I strongly suggest you to go read about Multinomial Bayes and think about why it works so well for \"Document Classification\", which is very similar to our case as every movie overview can be thought of as a document we are assigning labels to.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6 - Deep Learning : an intuitive overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results were good, but it's time to bring out the big guns. So first and foremost, let's get a very short idea about what's deep learning. This is for peope who don't have background in this - it's high level and gives just the intuition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described above, the two most immportant concepts in doing good classification (or regression) are to 1) use the right representation which captures the right information about the data which is relevant to the problem at hand 2) Using the right model which has the capability of making sense of the representation fed to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While for the second part we have complicated and powerful models that we have studied at length, we don't seem to have a principled, mathematical way of doing the first part - i.e. representation. What we did above was to see \"What makes sense\", and go from there. That is not a good approach for complex data/ complex problems. Is there some way to automate this? Deep Learning, does just this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To just emphasize the importance of representation in the complex tasks we usually attempt with Deep Learning, let me talk about the original problem which made it famous. The paper is often reffered to as the \"Imagenet Challenge Paper\", and it was basically working on object recognition in images. Let's try to think about an algorithm that tries to detect a chair. \n",
    "\n",
    "## If I ask you to \"Define\" a chair, how would you? - Something with 4 legs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/chair1.png\" height=\"400\" width=\"400\">\n",
    "<h3><center>All are chairs, none with 4 legs. (Pic Credit: Zoya Bylinskii)</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about some surface that we sit on then?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/chair2.png\" height=\"400\" width=\"400\">\n",
    "<h3><center>All are surfaces we sit on, none are chairs. (Pic Credit: Zoya Bylinskii)</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, these definitions won't work and we need something more complicated. Sadly, we can't come up with a simple text rule that our computer can search for! And we take a more principled approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Deep\" in the deep learning comes from the fact that it was conventionally applied to Neural Networks. Neural Networks, as we all know, are structures organized in layers. Layers of computations. Why do we need layers? Because these layers can be seen as sub-tasks that we do in the complicated task of identifying a chair. It can be thought as a heirarchical break down of a complicated job into smalled sub-tasks. \n",
    "\n",
    "Mathematically, each layer acts like a space transformation which takes the pixel values to a high dimensional space. When we start out, every pixel in the image is given equal importance in our matrix. With each layer, convolution operations give some parts more importance, and some lesser importance. In doing so, we transform our images to a space in which similar looking objects/object parts are closer (We are basically learning this space transformation in deep learning, nothing else)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What exactly was learnt by these neural networks is hard to know, and an active area of research. But one very crude way to visualize what it does is to think like - It starts by learning very generic features in the first layer. Something as simple as vertical and horizontal lines. In the next layer, it learns that if you combine the vectors representing vertical and horizontal vectors in different ratios, you can make all possible slanted lines. Next layer learns to combine lines to form curves - Say, something like the outline of a face. These curves come together to form 3D objects. And so on. Building sub-modules, combining them in the right way which can give it semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, in a nutshell, the first few layers of a \"Deep\" network learn the right representation of the data, given the problem (which is mathematically described by your objective function trying to minimize difference between ground truth and predicted labels). The last layer simply looks how close or far apart things are in this high dimensional space.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we can give any kind of data a high dimensional representation using neural networks. Below we will see high dimensional representations of both words in overviews (text) and posters (image). Let's get started with the posters i.e. extracting visual features from posters using deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7 - Deep Learning for predicting genre from poster\n",
    "\n",
    "Once again, we must make an implementation decision. This time, it has more to do with how much time are we willing to spend in return for added accuracy. We are going to use here a technique that is commonly referred to as Pre-Training in Machine Learning Literature. \n",
    "\n",
    "Instead of me trying to re-invent the wheel here, I am going to borrow this short section on pre-training from Stanford University's lecture on <a href='http://cs231n.github.io/transfer-learning/'> CNN's</a>. To quote - \n",
    "\n",
    "''In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest. ''\n",
    "\n",
    "There are three broad ways in which transfer learning or pre-training can be done. (The 2 concepts are different and to understand the difference clearly, I suggest you read the linked lecture thoroughly). The way we are going to about it is by using a pre-trained, released ConvNet as feature extractor. Take a ConvNet pretrained on ImageNet (a popular object detection dataset), remove the last fully-connected layer. After removing the last layer, what we have is just another neural network i.e. a stack of space tranformations. But, originally the output of this stack can be pumped into a single layer which can classify the image into categories like Car, Dog, Cat and so on.\n",
    "\n",
    "What this means, is that in the space this stack transforms the images to, all images which contain a \"dog\" are closer to each other, and all images containing a \"cat\" are closer. Thus, it is a meaningful space where images with similar objects are closer. \n",
    "\n",
    "Think about it, now if we pump our posters through this stack, it will embed them in a space where posters which contain similar objects are closer. This is a very meaningful feature engineering method! While this may not be ideal for genre prediction, it might be quite meaningful. For example, all posters with a gun or a car are probably action. While a smiling couple would point to romance or drama. The alternative would be to train the CNN from scratch which is fairly computationally intensive and involves a lot of tricks to get the CNN training to converge to the optimal space tranformation.\n",
    "\n",
    "This way, we can start off with something strong, and then build on top. We pump our images through the pre-trained network to extract the visual features from the posters. Then, using these features as descriptors for the image, and genres as the labels, we train a simpler neural network from scratch which learns to do simply classification on this dataset. These 2 steps are exactly what we are going to do for predicting genres from movie posters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning to extract visual features from posters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic problem here we are answering is that can we use the posters to predict genre. First check - Does this hypothesis make sense? Yes. Because that's what graphic designers do for a living. They leave visual cues to semantics. They make sure that when we look at the poster of a horror movie, we know it's not a happy image. Things like that. Can our deep learning system infer such subtleties? Let's find out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Visual features, either we can train a deep neural network ourselves from scratch, or we can use a pre-trained one made available to us from the Visual Geometry Group at Oxford University, one of the most popular methods. This is called the VGG-net. Or as they call it, we will extract the VGG features of an image. Mathematically, as mentioned, it's just a space transformation in the form of layers. So, we simply need to perform this chain of transformations on our image, right? We will be using Pytorch in this notebook. OTher alternatives are Keras and Tensorflow.\n",
    "\n",
    "\n",
    "We will be working with Keras to keep things simple in code, so that we can spend more time understanding and less time coding. Some common ways people refer to this step are - \"Getting the VGG features of an image\", or \"Forward Propogating the image through VGG and chopping off the last layer\". In keras, this is as easy as writing 4 lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the list of movies we had downloaded posters for eariler - \n",
    "f=open('poster_movies.pckl','r')\n",
    "poster_movies=pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "new_model = nn.Sequential(*list(vgg16.children())[:-1])\n",
    "model = nn.Sequential(*list(new_model.children())[:-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extracting VGG features for scraped images. This will take time, Please be patient...\n",
      "Total images =  1591\n",
      "Working on Image :  1\n",
      "Working on Image :  250\n",
      "Working on Image :  500\n",
      "Working on Image :  750\n",
      "Working on Image :  1000\n",
      "Working on Image :  1250\n",
      "Working on Image :  1500\n",
      "Working on Image :  1750\n",
      "Done with all features, please pickle for future use!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "allnames=os.listdir(poster_folder)\n",
    "imnames=[j for j in allnames if j.endswith('.jpg')]\n",
    "feature_list=[]\n",
    "genre_list=[]\n",
    "file_order=[]\n",
    "print \"Starting extracting VGG features for scraped images. This will take time, Please be patient...\"\n",
    "print \"Total images = \",len(imnames)\n",
    "failed_files=[]\n",
    "succesful_files=[]\n",
    "i=0\n",
    "\n",
    "for mov in poster_movies:\n",
    "    i+=1\n",
    "    mov_name=mov['original_title']\n",
    "    mov_name1=mov_name.replace(':','/')\n",
    "    poster_name=mov_name.replace(' ','_')+'.jpg'\n",
    "    if poster_name in imnames:\n",
    "        \n",
    "        img_path=poster_folder+poster_name\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            min_img_size = 224  # The min size, as noted in the PyTorch pretrained models doc, is 224 px.\n",
    "            transform_pipeline = transforms.Compose([transforms.Resize([min_img_size,min_img_size]),\n",
    "                                                     transforms.ToTensor(),\n",
    "                                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                          std=[0.229, 0.224, 0.225])])\n",
    "            img = transform_pipeline(img)\n",
    "            # PyTorch pretrained models expect the Tensor dims to be (num input imgs, num color channels, height, width).\n",
    "            # Currently however, we have (num color channels, height, width); let's fix this by inserting a new axis.\n",
    "#             print len(img)\n",
    "#             print img.shape\n",
    "#             print img\n",
    "#             break\n",
    "            img = img.unsqueeze(0)  # Insert the new axis at index 0 i.e. in front of the other axes/dims. \n",
    "            \n",
    "            \n",
    "            # Now that we have preprocessed our img, we need to convert it into a \n",
    "            # Variable; PyTorch models expect inputs to be Variables. A PyTorch Variable is a  \n",
    "            # wrapper around a PyTorch Tensor.\n",
    "            img = Variable(img)\n",
    "            succesful_files.append(poster_name)\n",
    "            \n",
    "            features = model(img)\n",
    "            #print features.shape\n",
    "            file_order.append(img_path)\n",
    "            feature_list.append(features)\n",
    "            genre_list.append(mov['genre_ids'])\n",
    "            max_prediction = features.data.numpy().argmax()  # Our prediction will be the index of the class label with the largest value.\n",
    "            if max_prediction==0.0:\n",
    "                print('problematic',i)\n",
    "            if i%250==0 or i==1:\n",
    "                print \"Working on Image : \",i\n",
    "        except:\n",
    "            failed_files.append(poster_name)\n",
    "            continue\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "print \"Done with all features, please pickle for future use!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1366"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1366"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features dumped to pickle file\n"
     ]
    }
   ],
   "source": [
    "# Reading from pickle below, this code is not to be run.\n",
    "list_pickled=(feature_list,file_order,failed_files,succesful_files,genre_list)\n",
    "f=open('posters_new_features.pckl','wb')\n",
    "pickle.dump(list_pickled,f)\n",
    "f.close()\n",
    "print(\"Features dumped to pickle file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "f7=open('posters_new_features.pckl','rb')\n",
    "list_pickled=pickle.load(f7)\n",
    "f7.close()\n",
    "# (feature_list2,file_order2)=list_pickled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a simple neural network model using these VGG features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "(feature_list,files,failed,succesful,genre_list)=list_pickled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first get the labels on our 1342 samples first! As image download fails on a few instances, the best way to work with the right model is to read the poster names downloaded, and working from there. These posters cannot be uploaded to Github as they are too large, and so are being downloaded and read from my local computer. If you do re-do it, you might have to check and edit the paths in the code to make sure it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a,b,c,d)=feature_list[0].shape\n",
    "feature_size=a*b*c*d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks odd, why are we re-running the loop we ran above again below? The reason is simple, the most important thing to know about numpy is that using vstack() and hstack() are highly sub-optimal. Numpy arrays when created, a fixed size is allocated in the memory and when we stack, a new one is copied and created in a new location. This makes the code really, really slow. The best way to do it (and this remains the same with MATLAB matrices if you work with them), is to create a numpy array of zeros, and over-write it row by row. The above code was just to see what size numpy array we will need!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final movie poster set for which we have all the information we need, is 1265 movies. In the above code we are making an X numpy array containing the visual features of one image per row. So, the VGG features are reshaped to be in the shape (1,25088) and we finally obtain a matrix of shape (1265,25088)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1366 150528\n"
     ]
    }
   ],
   "source": [
    "np_features=np.zeros((len(feature_list),feature_size))\n",
    "print len(feature_list),feature_size\n",
    "for i in range(len(feature_list)):\n",
    "    feat=feature_list[i]\n",
    "    reshaped_feat=feat.reshape(1,-1)\n",
    "    #print reshaped_feat.shape\n",
    "    np_features[i]=reshaped_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_features[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb=MultiLabelBinarizer()\n",
    "Y=mlb.fit_transform(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1366, 19)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our binarized Y numpy array contains the binarized labels corresponding to the genre IDs of the 1277 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_problem_data=(X,Y)\n",
    "f8=open('visual_problem_data_clean.pckl','wb')\n",
    "pickle.dump(visual_problem_data,f8)\n",
    "f8.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "f8=open('visual_problem_data_clean.pckl','rb')\n",
    "visual_features=pickle.load(f8)\n",
    "f8.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y)=visual_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1366, 150528)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.rand(len(X)) < 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85067213, -1.15891778, -1.56991184, ..., -1.54300654,\n",
       "        -1.54300654, -1.54300654],\n",
       "       [-1.72403467, -1.62128615, -1.46716332, ..., -1.43843138,\n",
       "        -1.43843138, -1.43843138],\n",
       "       [ 2.0776608 ,  2.0776608 ,  2.0776608 , ..., -0.68897593,\n",
       "        -0.70640522, -0.67154676],\n",
       "       ...,\n",
       "       [-0.85067213, -0.83354741, -0.8677969 , ..., -1.57786489,\n",
       "        -1.59529412, -1.59529412],\n",
       "       [ 1.7351656 , -0.06293353, -0.2855553 , ..., -0.28810447,\n",
       "        -0.41010883, -0.09638336],\n",
       "       [-1.70690989, -1.46716332, -1.17604256, ..., -1.49071896,\n",
       "        -1.49071896, -1.49071896]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=X[mask]\n",
    "X_test=X[~mask]\n",
    "Y_train=Y[mask]\n",
    "Y_test=Y[~mask]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 150528)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create our own keras neural network to use the VGG features and then classify movie genres. Keras makes this super easy. \n",
    "\n",
    "Neural network architectures have gotten complex over the years. But the simplest ones contain very standard computations organized in layers, as described above. Given the popularity of some of these, Keras makes it as easy as writing out the names of these operations in a sequential order. This way you can make a network while completely avoiding the Mathematics (HIGHLY RECOMMENDED SPENDING MORE TIME ON THE MATH THOUGH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential() allows us to make models the follow this sequential order of layers. Different kinds of layers like Dense, Conv2D etc can be used, and many activation functions like RELU, Linear etc are also available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Question : Why do we need activation functions?\n",
    "#### Copy pasting the answer I wrote for this question on <a href='https://www.quora.com/Why-do-neural-networks-need-an-activation-function/answer/Spandan-Madan?srid=5ydm'>Quora</a> Feel free to leave comments there.\n",
    "\n",
    "\"\"Sometimes, we tend to get lost in the jargon and confuse things easily, so the best way to go about this is getting back to our basics.\n",
    "\n",
    "Dont forget what the original premise of machine learning (and thus deep learning) is - IF the input and output are related by a function y=f(x), then if we have x, there is no way to exactly know f unless we know the process itself. However, machine learning gives you the ability to approximate f with a function g, and the process of trying out multiple candidates to identify the function g best approximating f is called machine learning.\n",
    "\n",
    "Ok, that was machine learning, and how is deep learning different? Deep learning simply tries to expand the possible kind of functions that can be approximated using the above mentioned machine learning paradigm. Roughly speaking, if the previous model could learn say 10,000 kinds of functions, now it will be able to learn say 100,000 kinds (in actuality both are infinite spaces but one is larger than the other, because maths is cool that ways.)\n",
    "\n",
    "If you want to know the mathematics of it, go read about VC dimension and how more layers in a network affect it. But I will avoid the mathematics here and rely on your intuition to believe me when I say that not all data can be classified correctly into categories using a linear function. So, we need our deep learning model to be able to approximate more complex functions than just a linear function.\n",
    "\n",
    "Now, lets come to your non linearity bit. Imagine a linear function y=2x+3, and another one y=4x+7. What happens if I pool them and take an average? I get another linear function y= 3x+5. So instead of doing those two computations separately and then averaging it out, I could have just used the single linear function y=3x+5. Obviously, this logic holds good if I have more than 2 such linear functions. This is exactly what will happen if you dont have have non-linearities in your nodes, and also what others have written in their answers.\n",
    "\n",
    "It simply follows from the definition of a linear function -\n",
    "\n",
    "(i) If you take two linear functions, AND\n",
    "\n",
    "(ii)Take a linear combination of them (which is how we combine the outputs of multiple nodes of a network)\n",
    "\n",
    "You are BOUND to get a linear function because f(x)+g(x)=mx+b+nx+c=(m+n)x+(b+c)= say h(x).\n",
    "\n",
    "And you could in essence replace your whole network by a simple matrix transformation which accounts for all linear combinations and up/downsamplings.\n",
    "\n",
    "In a nutshell, youll only be trying to learn a linear approximation for original function f relating the input and the output. Which as we discussed above, is not always the best approximation. Adding non-linearities ensures that you can learn more complex functions by approximating every non-linear function as a LINEAR combination of a large number of non-linear functions.\n",
    "\n",
    "Still new to the field, so if theres something wrong here please comment below! Hope it helps\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's train our model then, using the features we extracted from VGG net \n",
    "\n",
    "The model we will use has just 1 hidden layer between the VGG features and the final output layer. The simplest neural network you can get. An image goes into this network with the dimensions (1,25088), the first layer's output is 1024 dimensional. This hidden layer output undergoes a pointwise RELU activation. This output gets transformed into the output layer of 20 dimensions. It goes through a sigmoid.\n",
    "\n",
    "The sigmoid, or the squashing function as it is often called, is a function which squashes numbers between 0 and 1. What are you reminded of when you think of numebers between 0 and 1? Right, probability. \n",
    "\n",
    "By squashing the score of each of the 20 output labels between 0 and 1, sigmoid lets us interpret their scores as probabilities. Then, we can just pick the classes with the top 3 or 5 probability scores as the predicted genres for the movie poster! Simple! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train[115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.85067213 -1.15891778 -1.56991184 ... -1.54300654 -1.54300654\n",
      "  -1.54300654]\n",
      " [-1.72403467 -1.62128615 -1.46716332 ... -1.43843138 -1.43843138\n",
      "  -1.43843138]\n",
      " [ 2.0776608   2.0776608   2.0776608  ... -0.68897593 -0.70640522\n",
      "  -0.67154676]\n",
      " ...\n",
      " [-0.85067213 -0.83354741 -0.8677969  ... -1.57786489 -1.59529412\n",
      "  -1.59529412]\n",
      " [ 1.7351656  -0.06293353 -0.2855553  ... -0.28810447 -0.41010883\n",
      "  -0.09638336]\n",
      " [-1.70690989 -1.46716332 -1.17604256 ... -1.49071896 -1.49071896\n",
      "  -1.49071896]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Traceback (most recent call last):\n  File \"/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 173, in default_collate\n    return torch.stack([torch.from_numpy(b) for b in batch], 0)\nRuntimeError: Expected a Tensor of type torch.LongTensor but found a type torch.DoubleTensor for sequence element 1 in sequence argument at position #1 'tensors'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-d808645e9248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_visual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-137-d808645e9248>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdset_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Traceback (most recent call last):\n  File \"/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/anaconda3/envs/deeplearningproject/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 173, in default_collate\n    return torch.stack([torch.from_numpy(b) for b in batch], 0)\nRuntimeError: Expected a Tensor of type torch.LongTensor but found a type torch.DoubleTensor for sequence element 1 in sequence argument at position #1 'tensors'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import time\n",
    "def train_model(model, criterion, optimizer, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                mode='train'\n",
    "                #optimizer = lr_scheduler(optimizer, epoch)\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()\n",
    "                mode='val'\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            counter=0\n",
    "            # Iterate over data.\n",
    "            \n",
    "            for data in dset_loaders[phase]:\n",
    "                \n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    try:\n",
    "                        inputs, labels = Variable(inputs.float().cuda()),                             \n",
    "                        Variable(labels.long().cuda())\n",
    "                    except:\n",
    "                        print(inputs,labels)\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # Set gradient to zero to delete history of computations in previous epoch. Track operations so that differentiation can be done automatically.\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                print('loss done')                \n",
    "                # Just so that you can keep track that something's happening and don't feel like the program isn't running.\n",
    "                if counter%50==0:\n",
    "                    print(\"Reached iteration \",counter)\n",
    "                counter+=1\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    print('loss backward')\n",
    "                    loss.backward()\n",
    "                    print('done loss backward')\n",
    "                    optimizer.step()\n",
    "                    print('done optim')\n",
    "                # print evaluation statistics\n",
    "                try:\n",
    "                    running_loss += loss.data[0]\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                except:\n",
    "                    print('unexpected error, could not calculate loss or do a sum.')\n",
    "            print('trying epoch loss')\n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dset_sizes[phase]\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                if USE_TENSORBOARD:\n",
    "                    foo.add_scalar_value('epoch_loss',epoch_loss,step=epoch)\n",
    "                    foo.add_scalar_value('epoch_acc',epoch_acc,step=epoch)\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model = copy.deepcopy(model)\n",
    "                    print('new best accuracy = ',best_acc)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print('returning and looping back')\n",
    "    return best_model\n",
    "\n",
    "image_datasets = {}\n",
    "image_datasets['train'] = [X_train,Y_train]\n",
    "image_datasets['test'] = [X_test,Y_test]\n",
    "\n",
    "dset_loaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test']}\n",
    "\n",
    "\n",
    "model_visual = nn.Sequential(\n",
    "    nn.Linear(25088,1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,20),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "# #opt = optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "optimizer = torch.optim.RMSprop(model_visual.parameters(), lr=0.0001, weight_decay=1e-6)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model_ft = train_model(model_visual.double(), criterion.double(), optimizer, num_epochs=10)\n",
    "\n",
    "# Save model\n",
    "model_ft.save_state_dict('fine_tuned_best_model.pt')\n",
    "# #sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.4, nesterov=False)\n",
    "# model_visual.compile(optimizer=opt,\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model using the fit() function. The parameters it takes are - training features and training labels, epochs, batch_size and verbose. \n",
    "\n",
    "Simplest one - verbose. 0=\"dont print anything as you work\", 1=\"Inform me as you go\". \n",
    "\n",
    "Often the data set is too large to be loaded into the RAM. So, we load data in batches. For batch_size=32 and epochs=10, the model starts loading rows from X in batches of 32 everytime it calculates the loss and updates the model. It keeps on going till it has covered all the samples 10 times. \n",
    "\n",
    "So, the no. of times model is updated = (Total Samples/Batch Size) * (Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_visual.fit(X_train, Y_train, epochs=10, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_visual.fit(X_train, Y_train, epochs=50, batch_size=64,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first 10 epochs I trained the model in a verbose fashion to show you what's happening. After that, in the below cell you can see I turned off the verbosity to keep the code cleaner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_preds=model_visual.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sum(Y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at some of our predictions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f6=open('Genredict.pckl','rb')\n",
    "Genre_ID_to_name=pickle.load(f6)\n",
    "f6.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Y_preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Y_preds[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list=sorted(list(Genre_ID_to_name.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precs=[]\n",
    "recs=[]\n",
    "for i in range(len(Y_preds)):\n",
    "    row=Y_preds[i]\n",
    "    gt_genres=Y_test[i]\n",
    "    gt_genre_names=[]\n",
    "    for j in range(20):\n",
    "        if gt_genres[j]==1:\n",
    "            gt_genre_names.append(Genre_ID_to_name[genre_list[j]])\n",
    "    top_3=np.argsort(row)[-3:]\n",
    "    predicted_genres=[]\n",
    "    for genre in top_3:\n",
    "        predicted_genres.append(Genre_ID_to_name[genre_list[genre]])\n",
    "    (precision,recall)=precision_recall(gt_genre_names,predicted_genres)\n",
    "    precs.append(precision)\n",
    "    recs.append(recall)\n",
    "    if i%50==0:\n",
    "        print \"Predicted: \",','.join(predicted_genres),\" Actual: \",','.join(gt_genre_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.mean(np.asarray(precs)),np.mean(np.asarray(recs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, even with just the poster i.e. visual features we are able to make great predictions! Sure, text outperforms the visual features, but the important thing is that it still works. In more complicated models, we can combine the two to make even better predictions. That is precisely what I work on in my research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models were trained on CPU's, and a simple 1 layer model was used to show that there is a lot of information in this data that the models can extract. With a larger dataset, and more training I was able to bring these numbers to as high as 70%, which is the similar to textual features. Some teams in my class outperformed this even more. More data is the first thing you should try if you want better results. Then, you can start playing with training on GPUs, learning rate schedules and other hyperparameters. Finally, you can consider using ResNet, a much more powerful neural network model than VGG. All of these can be tried once you have a working knowledge of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 8 - Deep Learning to get Textual Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same thing as above with text now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an off the shelf representation for words - Word2Vec model. Just like VGGnet before, this is a model made available to get a meaningful representation. As the total number of words is small, we don't even need to forward propagate our sample through a network. Even that has been done for us, and the result is stored in the form of a dictionary. We can simply look up the word in the dictionary and get the Word2Vec features for the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the dictionary from here - https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit <br>\n",
    "Download it to the directory of this tutorial i.e. in the same folder as this ipython notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "# model2 = models.Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True) \n",
    "model2 = models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can simply look up for a word in the above loaded model. For example, to get the Word2Vec representation of the word \"King\" we just do - model2['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print model2['king'].shape\n",
    "print model2['dog'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we can represent the words in our overviews using this word2vec model. And then, we can use that as our X representations. So, instead of count of words, we are using a representation which is based on the semantic representation of the word. Mathematically, each word went from 3-4 dimensional (the length) to 300 dimensions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the same set of movies above, let's try and predict the genres from the deep representation of their overviews!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_movies_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_mean_wordvec=np.zeros((len(final_movies_set),300))\n",
    "movie_mean_wordvec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text needs some pre-processing before we can train the model. The only preprocessing we do here is - we delete commonly occurring words which we know are not informative about the genre. Think of it as the clutter in some sense. These words are often removed and are referred to as \"stop words\". You can look them up online. These include simple words like \"a\", \"and\", \"but\", \"how\", \"or\" and so on. They can be easily removed using the python package NLTK.\n",
    "\n",
    "From the above dataset, movies with overviews which contain only stop words, or movies with overviews containing no words with word2vec representation are neglected. Others are used to build our Mean word2vec representation. Simply, put for every movie overview - \n",
    "\n",
    "* Take movie overview\n",
    "* Throw out stop words\n",
    "* For non stop words:\n",
    "    - If in word2vec - take it's word2vec representation which is 300 dimensional\n",
    "    - If not - throw word\n",
    "* For each movie, calculate the arithmetic mean of the 300 dimensional vector representations for all words in the overview which weren't thrown out\n",
    "\n",
    "This mean becomes the 300 dimensional representation for the movie. For all movies, these are stored in a numpy array. So the X matrix becomes (1263,300). And, Y is (1263,20) i.e. binarized 20 genres, as before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why do we take the arithmetic mean?**\n",
    "If you feel that we should have kept all the words separately - Then you're thinking correct, but sadly we're limited by the way current day neural networks work. I will not mull over this for the fear of stressing too much on an otherwise irrelevant detail. But if you're interested, read this awesome paper - \n",
    "https://jiajunwu.com/papers/dmil_cvpr.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres=[]\n",
    "rows_to_delete=[]\n",
    "for i in range(len(final_movies_set)):\n",
    "    mov=final_movies_set[i]\n",
    "    movie_genres=mov['genre_ids']\n",
    "    genres.append(movie_genres)\n",
    "    overview=mov['overview']\n",
    "    tokens = tokenizer.tokenize(overview)\n",
    "    stopped_tokens = [k for k in tokens if not k in en_stop]\n",
    "    count_in_vocab=0\n",
    "    s=0\n",
    "    if len(stopped_tokens)==0:\n",
    "        rows_to_delete.append(i)\n",
    "        genres.pop(-1)\n",
    "#         print overview\n",
    "#         print \"sample \",i,\"had no nonstops\"\n",
    "    else:\n",
    "        for tok in stopped_tokens:\n",
    "            if tok.lower() in model2.vocab:\n",
    "                count_in_vocab+=1\n",
    "                s+=model2[tok.lower()]\n",
    "        if count_in_vocab!=0:\n",
    "            movie_mean_wordvec[i]=s/float(count_in_vocab)\n",
    "        else:\n",
    "            rows_to_delete.append(i)\n",
    "            genres.pop(-1)\n",
    "#             print overview\n",
    "#             print \"sample \",i,\"had no word2vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2=[]\n",
    "for row in range(len(movie_mean_wordvec)):\n",
    "    if row in rows_to_delete:\n",
    "        mask2.append(False)\n",
    "    else:\n",
    "        mask2.append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=movie_mean_wordvec[mask2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=mlb.fit_transform(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textual_features=(X,Y)\n",
    "f9=open('textual_features.pckl','wb')\n",
    "pickle.dump(textual_features,f9)\n",
    "f9.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textual_features=(X,Y)\n",
    "f9=open('textual_features.pckl','rb')\n",
    "textual_features=pickle.load(f9)\n",
    "f9.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y)=textual_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_text=np.random.rand(len(X))<0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X[mask_text]\n",
    "Y_train=Y[mask_text]\n",
    "X_test=X[~mask_text]\n",
    "Y_test=Y[~mask_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we use a very similar, super simple architecture as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model_textual = Sequential([\n",
    "    Dense(300, input_shape=(300,)),\n",
    "    Activation('relu'),\n",
    "    Dense(20),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "model_textual.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_textual.fit(X_train, Y_train, epochs=10, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_textual.fit(X_train, Y_train, epochs=10000, batch_size=500,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_textual.evaluate(X_test, Y_test, batch_size=249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%s: %.2f%%\" % (model_textual.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_preds=model_textual.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list.append(10769)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Our predictions for the movies are - \\n\"\n",
    "precs=[]\n",
    "recs=[]\n",
    "for i in range(len(Y_preds)):\n",
    "    row=Y_preds[i]\n",
    "    gt_genres=Y_test[i]\n",
    "    gt_genre_names=[]\n",
    "    for j in range(20):\n",
    "        if gt_genres[j]==1:\n",
    "            gt_genre_names.append(Genre_ID_to_name[genre_list[j]])\n",
    "    top_3=np.argsort(row)[-3:]\n",
    "    predicted_genres=[]\n",
    "    for genre in top_3:\n",
    "        predicted_genres.append(Genre_ID_to_name[genre_list[genre]])\n",
    "    (precision,recall)=precision_recall(gt_genre_names,predicted_genres)\n",
    "    precs.append(precision)\n",
    "    recs.append(recall)\n",
    "    if i%50==0:\n",
    "        print \"Predicted: \",predicted_genres,\" Actual: \",gt_genre_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.mean(np.asarray(precs)),np.mean(np.asarray(recs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even without much tuning of the above model, these results are able to beat our previous results. \n",
    "\n",
    "Note - I got accuracies as high as 78% when doing classification using plots scraped from Wikipedia. The large amount of information was very suitable for movie genre classification with a deep model. Strongly suggest you to try playing around with architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 9 - Upcoming Tutorials and Acknowledgements\n",
    "\n",
    "Congrats! This is the end of our pilot project! Needless to say, a lot of the above content may be new to you, or may be things that you know very well. If it's the former, I hope this tutorial would have helped you. If it is the latter and you think I wrote something incorrect or that my understanding can be improved, feel free to create a github issue so that I can correct it! \n",
    "\n",
    "Writing tutorials can take a lot of time, but it is a great learning experience. I am currently working on a tutorial focussing on word embeddings, which will explore word2vec and other word embeddings in detail. While it will take some time to be up, I will post a link to it's repository on the README for this project so that interested readers can find it.\n",
    "\n",
    "I would like to thank a few of my friends who had an indispensible role to play in me making this tutorial. Firstly, Professor Hanspeter Pfister and Verena Kaynig at Harvard, who helped guide this tutorial/project and scope it. Secondly, my friends Sahil Loomba and Matthew Tancik for their suggestions and editing the material and the presentation of the storyline. Thirdly, Zoya Bylinskii at MIT for constantly motivating me to put in my effort into this tutorial. Finally, all others who helped me feel confident enough to take up this task and to see it till the end. Thanks all of you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearningproject",
   "language": "python",
   "name": "deeplearningproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
